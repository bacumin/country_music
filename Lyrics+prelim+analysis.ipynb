{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Connection object at 0x000002278CC03E30>\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('C:/JupData/mxm_dataset.db')\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0x000002278CF0FCE0>\n"
     ]
    }
   ],
   "source": [
    "res = conn.execute(\"SELECT * FROM sqlite_master WHERE type='table'\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_tmdb = sqlite3.connect('C:/JupData/track_metadata.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('table', 'words', 'words', 2, 'CREATE TABLE words (word TEXT PRIMARY KEY)'),\n",
       " ('table',\n",
       "  'lyrics',\n",
       "  'lyrics',\n",
       "  4,\n",
       "  'CREATE TABLE lyrics (track_id, mxm_tid INT, word TEXT, count INT, is_test INT, FOREIGN KEY(word) REFERENCES words(word))')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around in sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn.execute(\"SELECT word FROM words\")\n",
    "len(res.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn.execute(\"SELECT word FROM words WHERE ROWID BETWEEN 50 AND 60\")\n",
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn.execute(\"SELECT track_id FROM lyrics WHERE word='countdown' ORDER BY RANDOM() LIMIT 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = conn_tmdb.execute(\"SELECT artist_name, title FROM songs WHERE track_id='TRCKLDK12903CEA5A9'\")\n",
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Got sick of SQL and switched to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Import data - select quantity with the number after \"limit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import words data\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_sql_query(\"select * from lyrics limit 50000000;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19045332, 5)\n",
      "                    track_id  mxm_tid    word  count  is_test\n",
      "19045327  TRZZZZD128F4236844  2466899  easili      1        1\n",
      "19045328  TRZZZZD128F4236844  2466899  disast      1        1\n",
      "19045329  TRZZZZD128F4236844  2466899   frown      1        1\n",
      "19045330  TRZZZZD128F4236844  2466899    teas      1        1\n",
      "19045331  TRZZZZD128F4236844  2466899   upset      1        1\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.tail())\n",
    "print(len(df['word'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import track information data to maps track id to title\n",
    "\n",
    "df_meta=pd.read_sql_query(\"SELECT * from songs limit 5000000;\", conn_tmdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c53e815d500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_meta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_meta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_meta' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_meta.shape)\n",
    "print(df_meta.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_titles=df_meta.merge(df, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(df_titles.shape, '\\n', df_titles[df_titles['track_id']=='TRAAPKW128F428BC93'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_titles.drop(labels=['song_id', 'shs_perf', 'shs_work', 'mxm_tid'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> first genres dataset, didn't end up using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first genres dataset\n",
    "\n",
    "df_genres=pd.read_csv('C:\\JupData\\msd-topMAGD-genreAssignment.cls', delimiter=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_genres.columns=['track_id','genre']\n",
    "print(df_genres.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_genres[df_genres['genre']=='Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> second genre dataset, nicer (more merges) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_genres2=pd.read_csv('C:\\JupData\\msd_tagtraum_cd1.cls', delimiter=\"\\t\", skiprows=8, usecols=[0,1], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             track_id       genre\n",
      "0  TRAAAAW128F429D538         Rap\n",
      "1  TRAAABD128F429CF47    Pop_Rock\n",
      "2  TRAAAED128E0783FAB        Jazz\n",
      "3  TRAAAEF128F4273421    Pop_Rock\n",
      "4  TRAAAEM128F93347B9  Electronic\n"
     ]
    }
   ],
   "source": [
    "df_genres2.columns=['track_id', 'genre']\n",
    "print(df_genres2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> merging genres data with titles and words data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged=df_titles.merge(df_genres2, on='track_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5215622, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             track_id           title         release           artist_id  \\\n",
      "0  TRMMMNO128F93539AA  In The Journey  In The Journey  AR4TLW81187B99683D   \n",
      "\n",
      "                            artist_mbid    artist_name   duration  \\\n",
      "0  0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "\n",
      "   artist_familiarity  artist_hotttnesss  year  track_7digitalid word  count  \\\n",
      "0            0.641198           0.448653  2001           5749967    i     30   \n",
      "\n",
      "   is_test genre  \n",
      "0        0  Folk  \n"
     ]
    }
   ],
   "source": [
    "print(df_merged.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checking that we have enough country data, making sure the data looks ok\n",
    "\n",
    "import numpy as np\n",
    "df_merged['is_country'] = np.where((df_merged['genre'] ==  'Country') | (df_merged['genre']=='Folk'), 1,0)\n",
    "\n",
    "#df_merged['is_country']=0\n",
    "#df_merged['is_country'][df_merged['genre']=='Country']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop_Rock         3610146\n",
      "Rap               510046\n",
      "Country           283100\n",
      "RnB               217097\n",
      "Electronic        165838\n",
      "Folk              120531\n",
      "Reggae             92112\n",
      "Latin              81019\n",
      "Jazz               64214\n",
      "Blues              42939\n",
      "International      14898\n",
      "Vocal               7277\n",
      "New Age             6405\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_merged.genre.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   track_id                     title  \\\n",
      "0        TRMMMNO128F93539AA            In The Journey   \n",
      "1        TRMMMNO128F93539AA            In The Journey   \n",
      "2        TRMMMNO128F93539AA            In The Journey   \n",
      "3        TRMMMNO128F93539AA            In The Journey   \n",
      "4        TRMMMNO128F93539AA            In The Journey   \n",
      "5        TRMMMNO128F93539AA            In The Journey   \n",
      "6        TRMMMNO128F93539AA            In The Journey   \n",
      "7        TRMMMNO128F93539AA            In The Journey   \n",
      "8        TRMMMNO128F93539AA            In The Journey   \n",
      "9        TRMMMNO128F93539AA            In The Journey   \n",
      "10       TRMMMNO128F93539AA            In The Journey   \n",
      "11       TRMMMNO128F93539AA            In The Journey   \n",
      "12       TRMMMNO128F93539AA            In The Journey   \n",
      "13       TRMMMNO128F93539AA            In The Journey   \n",
      "14       TRMMMNO128F93539AA            In The Journey   \n",
      "15       TRMMMNO128F93539AA            In The Journey   \n",
      "16       TRMMMNO128F93539AA            In The Journey   \n",
      "17       TRMMMNO128F93539AA            In The Journey   \n",
      "18       TRMMMNO128F93539AA            In The Journey   \n",
      "19       TRMMMNO128F93539AA            In The Journey   \n",
      "20       TRMMMNO128F93539AA            In The Journey   \n",
      "21       TRMMMNO128F93539AA            In The Journey   \n",
      "22       TRMMMNO128F93539AA            In The Journey   \n",
      "23       TRMMMNO128F93539AA            In The Journey   \n",
      "24       TRMMMNO128F93539AA            In The Journey   \n",
      "25       TRMMMNO128F93539AA            In The Journey   \n",
      "26       TRMMMNO128F93539AA            In The Journey   \n",
      "27       TRMMMNO128F93539AA            In The Journey   \n",
      "28       TRMMMNO128F93539AA            In The Journey   \n",
      "29       TRMMMNO128F93539AA            In The Journey   \n",
      "...                     ...                       ...   \n",
      "5214595  TRYYVOR128F92F097C  I Can't Love You Anymore   \n",
      "5214596  TRYYVOR128F92F097C  I Can't Love You Anymore   \n",
      "5214597  TRYYVOR128F92F097C  I Can't Love You Anymore   \n",
      "5214598  TRYYVOR128F92F097C  I Can't Love You Anymore   \n",
      "5214599  TRYYVOR128F92F097C  I Can't Love You Anymore   \n",
      "5214600  TRYYVOR128F92F097C  I Can't Love You Anymore   \n",
      "5215045  TRYYOLH128F425B68D                 The Angle   \n",
      "5215046  TRYYOLH128F425B68D                 The Angle   \n",
      "5215047  TRYYOLH128F425B68D                 The Angle   \n",
      "5215048  TRYYOLH128F425B68D                 The Angle   \n",
      "5215049  TRYYOLH128F425B68D                 The Angle   \n",
      "5215050  TRYYOLH128F425B68D                 The Angle   \n",
      "5215051  TRYYOLH128F425B68D                 The Angle   \n",
      "5215052  TRYYOLH128F425B68D                 The Angle   \n",
      "5215053  TRYYOLH128F425B68D                 The Angle   \n",
      "5215054  TRYYOLH128F425B68D                 The Angle   \n",
      "5215055  TRYYOLH128F425B68D                 The Angle   \n",
      "5215056  TRYYOLH128F425B68D                 The Angle   \n",
      "5215057  TRYYOLH128F425B68D                 The Angle   \n",
      "5215058  TRYYOLH128F425B68D                 The Angle   \n",
      "5215059  TRYYOLH128F425B68D                 The Angle   \n",
      "5215060  TRYYOLH128F425B68D                 The Angle   \n",
      "5215061  TRYYOLH128F425B68D                 The Angle   \n",
      "5215062  TRYYOLH128F425B68D                 The Angle   \n",
      "5215063  TRYYOLH128F425B68D                 The Angle   \n",
      "5215064  TRYYOLH128F425B68D                 The Angle   \n",
      "5215065  TRYYOLH128F425B68D                 The Angle   \n",
      "5215066  TRYYOLH128F425B68D                 The Angle   \n",
      "5215067  TRYYOLH128F425B68D                 The Angle   \n",
      "5215068  TRYYOLH128F425B68D                 The Angle   \n",
      "\n",
      "                               release           artist_id  \\\n",
      "0                       In The Journey  AR4TLW81187B99683D   \n",
      "1                       In The Journey  AR4TLW81187B99683D   \n",
      "2                       In The Journey  AR4TLW81187B99683D   \n",
      "3                       In The Journey  AR4TLW81187B99683D   \n",
      "4                       In The Journey  AR4TLW81187B99683D   \n",
      "5                       In The Journey  AR4TLW81187B99683D   \n",
      "6                       In The Journey  AR4TLW81187B99683D   \n",
      "7                       In The Journey  AR4TLW81187B99683D   \n",
      "8                       In The Journey  AR4TLW81187B99683D   \n",
      "9                       In The Journey  AR4TLW81187B99683D   \n",
      "10                      In The Journey  AR4TLW81187B99683D   \n",
      "11                      In The Journey  AR4TLW81187B99683D   \n",
      "12                      In The Journey  AR4TLW81187B99683D   \n",
      "13                      In The Journey  AR4TLW81187B99683D   \n",
      "14                      In The Journey  AR4TLW81187B99683D   \n",
      "15                      In The Journey  AR4TLW81187B99683D   \n",
      "16                      In The Journey  AR4TLW81187B99683D   \n",
      "17                      In The Journey  AR4TLW81187B99683D   \n",
      "18                      In The Journey  AR4TLW81187B99683D   \n",
      "19                      In The Journey  AR4TLW81187B99683D   \n",
      "20                      In The Journey  AR4TLW81187B99683D   \n",
      "21                      In The Journey  AR4TLW81187B99683D   \n",
      "22                      In The Journey  AR4TLW81187B99683D   \n",
      "23                      In The Journey  AR4TLW81187B99683D   \n",
      "24                      In The Journey  AR4TLW81187B99683D   \n",
      "25                      In The Journey  AR4TLW81187B99683D   \n",
      "26                      In The Journey  AR4TLW81187B99683D   \n",
      "27                      In The Journey  AR4TLW81187B99683D   \n",
      "28                      In The Journey  AR4TLW81187B99683D   \n",
      "29                      In The Journey  AR4TLW81187B99683D   \n",
      "...                                ...                 ...   \n",
      "5214595           The Road To Ensenada  ARTMDQM1187B9B8007   \n",
      "5214596           The Road To Ensenada  ARTMDQM1187B9B8007   \n",
      "5214597           The Road To Ensenada  ARTMDQM1187B9B8007   \n",
      "5214598           The Road To Ensenada  ARTMDQM1187B9B8007   \n",
      "5214599           The Road To Ensenada  ARTMDQM1187B9B8007   \n",
      "5214600           The Road To Ensenada  ARTMDQM1187B9B8007   \n",
      "5215045  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215046  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215047  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215048  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215049  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215050  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215051  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215052  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215053  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215054  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215055  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215056  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215057  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215058  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215059  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215060  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215061  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215062  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215063  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215064  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215065  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215066  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215067  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "5215068  Blank Unstaring Heirs Of Doom  ARJT53O1187FB5641F   \n",
      "\n",
      "                                  artist_mbid    artist_name   duration  \\\n",
      "0        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "1        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "2        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "3        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "4        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "5        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "6        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "7        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "8        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "9        0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "10       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "11       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "12       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "13       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "14       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "15       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "16       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "17       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "18       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "19       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "20       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "21       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "22       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "23       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "24       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "25       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "26       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "27       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "28       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "29       0685ac4a-5cfc-408a-b391-903ea20e00bf  Martin Sexton  319.81669   \n",
      "...                                       ...            ...        ...   \n",
      "5214595  7241e3ed-5ad4-4849-94df-6858ea833472    Lyle Lovett  194.35057   \n",
      "5214596  7241e3ed-5ad4-4849-94df-6858ea833472    Lyle Lovett  194.35057   \n",
      "5214597  7241e3ed-5ad4-4849-94df-6858ea833472    Lyle Lovett  194.35057   \n",
      "5214598  7241e3ed-5ad4-4849-94df-6858ea833472    Lyle Lovett  194.35057   \n",
      "5214599  7241e3ed-5ad4-4849-94df-6858ea833472    Lyle Lovett  194.35057   \n",
      "5214600  7241e3ed-5ad4-4849-94df-6858ea833472    Lyle Lovett  194.35057   \n",
      "5215045  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215046  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215047  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215048  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215049  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215050  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215051  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215052  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215053  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215054  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215055  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215056  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215057  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215058  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215059  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215060  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215061  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215062  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215063  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215064  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215065  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215066  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215067  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "5215068  6a8c6183-b9b3-41f4-b101-2294adac0b3a    Jana Hunter  140.12036   \n",
      "\n",
      "         artist_familiarity  artist_hotttnesss  year  track_7digitalid  \\\n",
      "0                  0.641198           0.448653  2001           5749967   \n",
      "1                  0.641198           0.448653  2001           5749967   \n",
      "2                  0.641198           0.448653  2001           5749967   \n",
      "3                  0.641198           0.448653  2001           5749967   \n",
      "4                  0.641198           0.448653  2001           5749967   \n",
      "5                  0.641198           0.448653  2001           5749967   \n",
      "6                  0.641198           0.448653  2001           5749967   \n",
      "7                  0.641198           0.448653  2001           5749967   \n",
      "8                  0.641198           0.448653  2001           5749967   \n",
      "9                  0.641198           0.448653  2001           5749967   \n",
      "10                 0.641198           0.448653  2001           5749967   \n",
      "11                 0.641198           0.448653  2001           5749967   \n",
      "12                 0.641198           0.448653  2001           5749967   \n",
      "13                 0.641198           0.448653  2001           5749967   \n",
      "14                 0.641198           0.448653  2001           5749967   \n",
      "15                 0.641198           0.448653  2001           5749967   \n",
      "16                 0.641198           0.448653  2001           5749967   \n",
      "17                 0.641198           0.448653  2001           5749967   \n",
      "18                 0.641198           0.448653  2001           5749967   \n",
      "19                 0.641198           0.448653  2001           5749967   \n",
      "20                 0.641198           0.448653  2001           5749967   \n",
      "21                 0.641198           0.448653  2001           5749967   \n",
      "22                 0.641198           0.448653  2001           5749967   \n",
      "23                 0.641198           0.448653  2001           5749967   \n",
      "24                 0.641198           0.448653  2001           5749967   \n",
      "25                 0.641198           0.448653  2001           5749967   \n",
      "26                 0.641198           0.448653  2001           5749967   \n",
      "27                 0.641198           0.448653  2001           5749967   \n",
      "28                 0.641198           0.448653  2001           5749967   \n",
      "29                 0.641198           0.448653  2001           5749967   \n",
      "...                     ...                ...   ...               ...   \n",
      "5214595            0.696864           0.536945  1996           4878328   \n",
      "5214596            0.696864           0.536945  1996           4878328   \n",
      "5214597            0.696864           0.536945  1996           4878328   \n",
      "5214598            0.696864           0.536945  1996           4878328   \n",
      "5214599            0.696864           0.536945  1996           4878328   \n",
      "5214600            0.696864           0.536945  1996           4878328   \n",
      "5215045            0.653041           0.439870  2005           2784112   \n",
      "5215046            0.653041           0.439870  2005           2784112   \n",
      "5215047            0.653041           0.439870  2005           2784112   \n",
      "5215048            0.653041           0.439870  2005           2784112   \n",
      "5215049            0.653041           0.439870  2005           2784112   \n",
      "5215050            0.653041           0.439870  2005           2784112   \n",
      "5215051            0.653041           0.439870  2005           2784112   \n",
      "5215052            0.653041           0.439870  2005           2784112   \n",
      "5215053            0.653041           0.439870  2005           2784112   \n",
      "5215054            0.653041           0.439870  2005           2784112   \n",
      "5215055            0.653041           0.439870  2005           2784112   \n",
      "5215056            0.653041           0.439870  2005           2784112   \n",
      "5215057            0.653041           0.439870  2005           2784112   \n",
      "5215058            0.653041           0.439870  2005           2784112   \n",
      "5215059            0.653041           0.439870  2005           2784112   \n",
      "5215060            0.653041           0.439870  2005           2784112   \n",
      "5215061            0.653041           0.439870  2005           2784112   \n",
      "5215062            0.653041           0.439870  2005           2784112   \n",
      "5215063            0.653041           0.439870  2005           2784112   \n",
      "5215064            0.653041           0.439870  2005           2784112   \n",
      "5215065            0.653041           0.439870  2005           2784112   \n",
      "5215066            0.653041           0.439870  2005           2784112   \n",
      "5215067            0.653041           0.439870  2005           2784112   \n",
      "5215068            0.653041           0.439870  2005           2784112   \n",
      "\n",
      "              word  count  is_test    genre  is_country  \n",
      "0                i     30        0     Folk           1  \n",
      "1              the     15        0     Folk           1  \n",
      "2              you      4        0     Folk           1  \n",
      "3               to      6        0     Folk           1  \n",
      "4              and     15        0     Folk           1  \n",
      "5                a      5        0     Folk           1  \n",
      "6               me      3        0     Folk           1  \n",
      "7               it     13        0     Folk           1  \n",
      "8              not     11        0     Folk           1  \n",
      "9               in      6        0     Folk           1  \n",
      "10              my      5        0     Folk           1  \n",
      "11              is      2        0     Folk           1  \n",
      "12              of      2        0     Folk           1  \n",
      "13            that      8        0     Folk           1  \n",
      "14              do     13        0     Folk           1  \n",
      "15              on      2        0     Folk           1  \n",
      "16             are      1        0     Folk           1  \n",
      "17              we     14        0     Folk           1  \n",
      "18              am      4        0     Folk           1  \n",
      "19             all      4        0     Folk           1  \n",
      "20              no      2        0     Folk           1  \n",
      "21            have      7        0     Folk           1  \n",
      "22            love      2        0     Folk           1  \n",
      "23            know     10        0     Folk           1  \n",
      "24             but      1        0     Folk           1  \n",
      "25            with      1        0     Folk           1  \n",
      "26            what      1        0     Folk           1  \n",
      "27            just      4        0     Folk           1  \n",
      "28             now      1        0     Folk           1  \n",
      "29             can      2        0     Folk           1  \n",
      "...            ...    ...      ...      ...         ...  \n",
      "5214595    whisper      2        0  Country           1  \n",
      "5214596       less      4        0  Country           1  \n",
      "5214597         ok      3        0  Country           1  \n",
      "5214598     easili      3        0  Country           1  \n",
      "5214599    georgia      2        0  Country           1  \n",
      "5214600   distress      3        0  Country           1  \n",
      "5215045          i      5        0     Folk           1  \n",
      "5215046        the      1        0     Folk           1  \n",
      "5215047          a      1        0     Folk           1  \n",
      "5215048        not      1        0     Folk           1  \n",
      "5215049         in      2        0     Folk           1  \n",
      "5215050         my      1        0     Folk           1  \n",
      "5215051         of      1        0     Folk           1  \n",
      "5215052         on      1        0     Folk           1  \n",
      "5215053         we      3        0     Folk           1  \n",
      "5215054       like      1        0     Folk           1  \n",
      "5215055         up      1        0     Folk           1  \n",
      "5215056       down     18        0     Folk           1  \n",
      "5215057         or      1        0     Folk           1  \n",
      "5215058       free      1        0     Folk           1  \n",
      "5215059       done      1        0     Folk           1  \n",
      "5215060     forget      1        0     Folk           1  \n",
      "5215061  yesterday      1        0     Folk           1  \n",
      "5215062      cloth      1        0     Folk           1  \n",
      "5215063      circl      1        0     Folk           1  \n",
      "5215064     suppos      1        0     Folk           1  \n",
      "5215065       deal      6        0     Folk           1  \n",
      "5215066        row      1        0     Folk           1  \n",
      "5215067      wrist      1        0     Folk           1  \n",
      "5215068   fragment      1        0     Folk           1  \n",
      "\n",
      "[403631 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_merged[df_merged['is_country']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#excluding pop rock\n",
    "df_merged2=df_merged[df_merged.genre!='Pop_Rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model=df_merged[['track_id', 'is_country', 'word', 'count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse matrix representation - efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>is_country</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>i</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>you</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>not</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>my</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>do</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>on</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>are</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>we</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>am</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>have</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>know</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>but</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>with</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>just</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>now</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TRMMMNO128F93539AA</td>\n",
       "      <td>1</td>\n",
       "      <td>can</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215592</th>\n",
       "      <td>TRYYYJD128F429528C</td>\n",
       "      <td>0</td>\n",
       "      <td>conscienc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215593</th>\n",
       "      <td>TRYYYJD128F429528C</td>\n",
       "      <td>0</td>\n",
       "      <td>roar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215594</th>\n",
       "      <td>TRYYYJD128F429528C</td>\n",
       "      <td>0</td>\n",
       "      <td>rumor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215595</th>\n",
       "      <td>TRYYYJD128F429528C</td>\n",
       "      <td>0</td>\n",
       "      <td>thirsti</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215596</th>\n",
       "      <td>TRYYYJD128F429528C</td>\n",
       "      <td>0</td>\n",
       "      <td>cope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215597</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215598</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215599</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215600</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>is</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215601</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215602</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>will</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215603</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>like</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215604</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>they</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215605</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>out</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215606</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>more</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215607</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>tell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215608</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>too</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215609</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>girl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215610</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>noth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215611</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>alway</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215612</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>end</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215613</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>much</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215614</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>than</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215615</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>boy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215616</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>dead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215617</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>big</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215618</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>fade</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215619</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>fun</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215620</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>fact</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215621</th>\n",
       "      <td>TRYYYFV128F4277D53</td>\n",
       "      <td>0</td>\n",
       "      <td>shove</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5215622 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   track_id  is_country       word  count\n",
       "0        TRMMMNO128F93539AA           1          i     30\n",
       "1        TRMMMNO128F93539AA           1        the     15\n",
       "2        TRMMMNO128F93539AA           1        you      4\n",
       "3        TRMMMNO128F93539AA           1         to      6\n",
       "4        TRMMMNO128F93539AA           1        and     15\n",
       "5        TRMMMNO128F93539AA           1          a      5\n",
       "6        TRMMMNO128F93539AA           1         me      3\n",
       "7        TRMMMNO128F93539AA           1         it     13\n",
       "8        TRMMMNO128F93539AA           1        not     11\n",
       "9        TRMMMNO128F93539AA           1         in      6\n",
       "10       TRMMMNO128F93539AA           1         my      5\n",
       "11       TRMMMNO128F93539AA           1         is      2\n",
       "12       TRMMMNO128F93539AA           1         of      2\n",
       "13       TRMMMNO128F93539AA           1       that      8\n",
       "14       TRMMMNO128F93539AA           1         do     13\n",
       "15       TRMMMNO128F93539AA           1         on      2\n",
       "16       TRMMMNO128F93539AA           1        are      1\n",
       "17       TRMMMNO128F93539AA           1         we     14\n",
       "18       TRMMMNO128F93539AA           1         am      4\n",
       "19       TRMMMNO128F93539AA           1        all      4\n",
       "20       TRMMMNO128F93539AA           1         no      2\n",
       "21       TRMMMNO128F93539AA           1       have      7\n",
       "22       TRMMMNO128F93539AA           1       love      2\n",
       "23       TRMMMNO128F93539AA           1       know     10\n",
       "24       TRMMMNO128F93539AA           1        but      1\n",
       "25       TRMMMNO128F93539AA           1       with      1\n",
       "26       TRMMMNO128F93539AA           1       what      1\n",
       "27       TRMMMNO128F93539AA           1       just      4\n",
       "28       TRMMMNO128F93539AA           1        now      1\n",
       "29       TRMMMNO128F93539AA           1        can      2\n",
       "...                     ...         ...        ...    ...\n",
       "5215592  TRYYYJD128F429528C           0  conscienc      1\n",
       "5215593  TRYYYJD128F429528C           0       roar      1\n",
       "5215594  TRYYYJD128F429528C           0      rumor      1\n",
       "5215595  TRYYYJD128F429528C           0    thirsti      3\n",
       "5215596  TRYYYJD128F429528C           0       cope      1\n",
       "5215597  TRYYYFV128F4277D53           0        the      1\n",
       "5215598  TRYYYFV128F4277D53           0        and      2\n",
       "5215599  TRYYYFV128F4277D53           0         it      2\n",
       "5215600  TRYYYFV128F4277D53           0         is      3\n",
       "5215601  TRYYYFV128F4277D53           0       that      2\n",
       "5215602  TRYYYFV128F4277D53           0       will      2\n",
       "5215603  TRYYYFV128F4277D53           0       like      2\n",
       "5215604  TRYYYFV128F4277D53           0       they      2\n",
       "5215605  TRYYYFV128F4277D53           0        out      4\n",
       "5215606  TRYYYFV128F4277D53           0       more      2\n",
       "5215607  TRYYYFV128F4277D53           0       tell      1\n",
       "5215608  TRYYYFV128F4277D53           0        too      2\n",
       "5215609  TRYYYFV128F4277D53           0       girl      2\n",
       "5215610  TRYYYFV128F4277D53           0       noth      2\n",
       "5215611  TRYYYFV128F4277D53           0      alway      2\n",
       "5215612  TRYYYFV128F4277D53           0        end      1\n",
       "5215613  TRYYYFV128F4277D53           0       much      2\n",
       "5215614  TRYYYFV128F4277D53           0       than      2\n",
       "5215615  TRYYYFV128F4277D53           0        boy      2\n",
       "5215616  TRYYYFV128F4277D53           0       dead      1\n",
       "5215617  TRYYYFV128F4277D53           0        big      2\n",
       "5215618  TRYYYFV128F4277D53           0       fade      6\n",
       "5215619  TRYYYFV128F4277D53           0        fun      2\n",
       "5215620  TRYYYFV128F4277D53           0       fact      2\n",
       "5215621  TRYYYFV128F4277D53           0      shove      2\n",
       "\n",
       "[5215622 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "track_sorted=sorted(df_model.track_id.unique())\n",
    "words_sorted=sorted(df_model.word.unique())\n",
    "\n",
    "track_id_u = list(track_sorted)\n",
    "word_u = list(words_sorted)\n",
    "\n",
    "data = df_model['count'].tolist()\n",
    "row = df_model.track_id.astype('category', categories=track_id_u).cat.codes\n",
    "col = df_model.word.astype('category', categories=word_u).cat.codes\n",
    "sparse_matrix = csr_matrix((data, (row, col)), shape=(len(track_id_u), len(word_u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=np.array(sparse_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_train=df_model.groupby('track_id', sort=False)['is_country'].agg('mean')\n",
    "y_train=np.array(y_train)\n",
    "print(y_train[2980:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).to_pickle('x_train.pickle')\n",
    "pd.DataFrame(y_train).to_pickle('y_train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TFIDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts=sparse_matrix.todense()\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "x_train_tfidf = TfidfTransformer(use_idf=False).fit_transform(counts)\n",
    "x_train=x_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra data pre-processing for more expensive models\n",
    "SVM, Logistic and RF take a while to run, and could be prone to overfitting. The code below only keeps the top \"top\" most popular words (change 1 cell down to implement this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lOAD IN PRELOADED DATASET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "x_train=pd.read_csv('x_train.csv')\n",
    "y_train=pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#REMOVE THIS LATER IF NO LONGER LOADING IN CSVS\n",
    "y_train.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Creates an array that sums up each column of x_train, sorts it, keeps the top x and subsets based on this\n",
    "#CHANGED TO DENSE LINE BECAUSE I LOADED IN A CSV\n",
    "#x_train_pd=pd.DataFrame(x_train.todense())\n",
    "x_train.index=x_train.iloc[:,0]\n",
    "x_train.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "x_train_pd=x_train\n",
    "x_train_sum=pd.DataFrame(x_train_pd.sum(axis=0))\n",
    "print(x_train_sum.shape)\n",
    "x_train_sum['idx']=range(len(x_train_sum))\n",
    "x_train_sum.sort_values(by=0, axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change top and the code below to exclude some observations.\n",
    "_from=0\n",
    "_to=1000\n",
    "keep_columns=x_train_sum.iloc[_from:_to]['idx']\n",
    "keep_columns_array=np.array(keep_columns)\n",
    "x_train_subset=x_train_pd.iloc[:,keep_columns_array]\n",
    "x_train2=np.array(x_train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words (the stop words list is at the end of the notebook, for style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4108600aab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#This significantly decreases our sample size :( hopefully it's all noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_model_nostop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_model_nostop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_model' is not defined"
     ]
    }
   ],
   "source": [
    "#This significantly decreases our sample size :( hopefully it's all noise\n",
    "df_model_nostop=df_model.loc[~df_model.word.isin(stop_words)]\n",
    "df_model_nostop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "track_sorted=sorted(df_model_nostop.track_id.unique())\n",
    "words_sorted=sorted(df_model_nostop.word.unique())\n",
    "\n",
    "track_id_u = list(track_sorted)\n",
    "word_u = list(words_sorted)\n",
    "\n",
    "data = df_model_nostop['count'].tolist()\n",
    "row = df_model_nostop.track_id.astype('category', categories=track_id_u).cat.codes\n",
    "col = df_model_nostop.word.astype('category', categories=word_u).cat.codes\n",
    "sparse_matrix_nostop = csr_matrix((data, (row, col)), shape=(len(track_id_u), len(word_u)))\n",
    "\n",
    "x_train_nostop=np.array(sparse_matrix_nostop.todense())\n",
    "y_train_nostop=df_model_nostop.groupby('track_id', sort=False)['is_country'].agg('mean')\n",
    "y_train_nostop=np.array(y_train_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm afraid of overfitting without stop words. Create a subset of the top non stop words (note the index is shorter because of removal of stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4897, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_nostop_pd=pd.DataFrame(x_train_nostop)\n",
    "x_train_nostop_sum=pd.DataFrame(x_train_nostop_pd.sum(axis=0))\n",
    "print(x_train_nostop_sum.shape)\n",
    "x_train_nostop_sum['idx']=range(len(x_train_nostop_sum))\n",
    "x_train_nostop_sum.sort_values(by=0, axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change top and the code below to exclude some observations.\n",
    "_from=0\n",
    "_to=1000\n",
    "keep_columns=x_train_nostop_sum.iloc[_from:_to]['idx']\n",
    "keep_columns_array=np.array(keep_columns)\n",
    "x_train_nostop_subset=x_train_nostop_pd.iloc[:,keep_columns_array]\n",
    "x_train_nostop2=np.array(x_train_nostop_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62689, 1000) (62689,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_nostop2.shape,y_train_nostop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with only stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726154, 4)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This significantly decreases our sample size :( hopefully it's all noise\n",
    "df_model_stop=df_model.loc[df_model.word.isin(stop_words)]\n",
    "df_model_stop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "track_sorted=sorted(df_model_stop.track_id.unique())\n",
    "words_sorted=sorted(df_model_stop.word.unique())\n",
    "\n",
    "track_id_u = list(track_sorted)\n",
    "word_u = list(words_sorted)\n",
    "\n",
    "data = df_model_stop['count'].tolist()\n",
    "row = df_model_stop.track_id.astype('category', categories=track_id_u).cat.codes\n",
    "col = df_model_stop.word.astype('category', categories=word_u).cat.codes\n",
    "sparse_matrix_stop = csr_matrix((data, (row, col)), shape=(len(track_id_u), len(word_u)))\n",
    "\n",
    "x_train_stop=np.array(sparse_matrix_stop.todense())\n",
    "y_train_stop=df_model_stop.groupby('track_id', sort=False)['is_country'].agg('mean')\n",
    "y_train_stop=np.array(y_train_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_test=PCA(n_components=10, whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_pca=pca_test.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27942661918653444"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca_test.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test/train split - choose data here. Options are:\n",
    "- x_train (all data, top 5k words)\n",
    "- x_train2 (all data, subset of words - see _from and _to 6 cells up)\n",
    "- x_train_nostop (no stop words)\n",
    "- x_train_nostop2 (no stop words, subset of words - see _from and _to 2 cells up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).to_csv('x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).to_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data import to skip above\n",
    "import pandas as pd\n",
    "y_train=pd.read_csv('y_train.csv')\n",
    "x_train=pd.read_csv('x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO CHANGE SAMPLE\n",
    "import numpy as np\n",
    "x=x_train\n",
    "y=np.array(y_train['0'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-33a8befdeac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    585\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    586\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "# Naive bayes \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "model1=MultinomialNB(fit_prior=False, alpha=1)\n",
    "model1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.92      0.93     17449\n",
      "          1       0.07      0.07      0.07      1359\n",
      "\n",
      "avg / total       0.87      0.86      0.86     18808\n",
      "\n",
      "[[16100  1349]\n",
      " [ 1259   100]]\n"
     ]
    }
   ],
   "source": [
    "#Metrics\n",
    "expected=Y_test\n",
    "predicted=model1.predict(X_test)\n",
    "print('training data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=300, max_features=200, max_depth=3, class_weight='auto', criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=3, max_features=200, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.80      0.86     17449\n",
      "          1       0.07      0.19      0.10      1359\n",
      "\n",
      "avg / total       0.86      0.76      0.80     18808\n",
      "\n",
      "[[13974  3475]\n",
      " [ 1106   253]]\n",
      "training data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.82      0.88     40722\n",
      "          1       0.17      0.48      0.25      3163\n",
      "\n",
      "avg / total       0.90      0.79      0.84     43885\n",
      "\n",
      "[[33305  7417]\n",
      " [ 1635  1528]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Metrics test\n",
    "expected=Y_test\n",
    "predicted=rf.predict(X_test)\n",
    "print('test data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "\n",
    "#Metrics train\n",
    "expected=Y_train\n",
    "predicted=rf.predict(X_train)\n",
    "print('training data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_train, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for z in rf.feature_importances_:\n",
    "    print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43885, 5001) (43885,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2=logit.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.59      0.72     17449\n",
      "          1       0.07      0.42      0.13      1359\n",
      "\n",
      "avg / total       0.87      0.58      0.68     18808\n",
      "\n",
      "[[10335  7114]\n",
      " [  790   569]]\n",
      "training data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.61      0.74     40722\n",
      "          1       0.10      0.56      0.17      3163\n",
      "\n",
      "avg / total       0.89      0.60      0.70     43885\n",
      "\n",
      "[[24694 16028]\n",
      " [ 1379  1784]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Metrics test\n",
    "expected=Y_test\n",
    "predicted=model2.predict(X_test)\n",
    "print('test data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "\n",
    "#Metrics train\n",
    "expected=Y_train\n",
    "predicted=model2.predict(X_train)\n",
    "print('training data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_train, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmlin=svm.LinearSVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model4=svmlin.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.67      0.78     17449\n",
      "          1       0.07      0.32      0.12      1359\n",
      "\n",
      "avg / total       0.86      0.65      0.73     18808\n",
      "\n",
      "[[11778  5671]\n",
      " [  930   429]]\n",
      "training data \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.68      0.79     40722\n",
      "          1       0.07      0.33      0.12      3163\n",
      "\n",
      "avg / total       0.87      0.66      0.74     43885\n",
      "\n",
      "[[27763 12959]\n",
      " [ 2126  1037]]\n"
     ]
    }
   ],
   "source": [
    "#Metrics test\n",
    "expected=Y_test\n",
    "predicted=model4.predict(X_test)\n",
    "print('test data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "\n",
    "#Metrics train\n",
    "expected=Y_train\n",
    "predicted=model4.predict(X_train)\n",
    "print('training data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_train, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM hyper paramater tuning\n",
    "maybe this will help with overfitting by adjusting the C parameter? Idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from __future__ import print_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "scores = ['precision', 'recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-abe3a9d8487f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n\u001b[1;32m      6\u001b[0m                        scoring='%s_macro' % score)\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     89\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[1;32m     90\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Baptiste\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Close sql connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()\n",
    "conn_tmdb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse matrix inefficient\n",
    "This is legacy code, it's ridiculously slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model_piv=df_model.pivot(index='track_id', columns='word', values='count')\n",
    "print(df_model_piv.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model_piv=df_model_piv.iloc[0:100000]\n",
    "df_model_piv.replace(to_replace='Nan', value=0, inplace=True)\n",
    "df_model_piv = df_model_piv.rename(columns={'word': 'track_id'})\n",
    "print(df_model_piv.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_is_country=df_merged[['track_id', 'is_country']]\n",
    "df_is_country=df_is_country.groupby(by='track_id', as_index=True).mean()\n",
    "print(df_is_country[df_is_country.is_country==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model_sparse=pd.merge(df_model_piv, df_is_country, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_model_sparse.to_csv('C:/JupData/abc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "y_train=np.array(df_model_sparse['is_country'])\n",
    "df_model_sparse.drop('is_country', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model_sparse.drop('track_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=np.array(df_model_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train[2860], y_train[2980:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words=[\"a\",\n",
    "\"about\",\n",
    "\"above\",\n",
    "\"after\",\n",
    "\"again\",\n",
    "\"against\",\n",
    "\"all\",\n",
    "\"am\",\n",
    "\"an\",\n",
    "\"and\",\n",
    "\"any\",\n",
    "\"are\",\n",
    "\"aren't\",\n",
    "\"as\",\n",
    "\"at\",\n",
    "\"be\",\n",
    "\"because\",\n",
    "\"been\",\n",
    "\"before\",\n",
    "\"being\",\n",
    "\"below\",\n",
    "\"between\",\n",
    "\"both\",\n",
    "\"but\",\n",
    "\"by\",\n",
    "\"can't\",\n",
    "\"cannot\",\n",
    "\"could\",\n",
    "\"couldn't\",\n",
    "\"did\",\n",
    "\"didn't\",\n",
    "\"do\",\n",
    "\"does\",\n",
    "\"doesn't\",\n",
    "\"doing\",\n",
    "\"don't\",\n",
    "\"down\",\n",
    "\"during\",\n",
    "\"each\",\n",
    "\"few\",\n",
    "\"for\",\n",
    "\"from\",\n",
    "\"further\",\n",
    "\"had\",\n",
    "\"hadn't\",\n",
    "\"has\",\n",
    "\"hasn't\",\n",
    "\"have\",\n",
    "\"haven't\",\n",
    "\"having\",\n",
    "\"he\",\n",
    "\"he'd\",\n",
    "\"he'll\",\n",
    "\"he's\",\n",
    "\"her\",\n",
    "\"here\",\n",
    "\"here's\",\n",
    "\"hers\",\n",
    "\"herself\",\n",
    "\"him\",\n",
    "\"himself\",\n",
    "\"his\",\n",
    "\"how\",\n",
    "\"how's\",\n",
    "\"i\",\n",
    "\"i'd\",\n",
    "\"i'll\",\n",
    "\"i'm\",\n",
    "\"i've\",\n",
    "\"if\",\n",
    "\"in\",\n",
    "\"into\",\n",
    "\"is\",\n",
    "\"isn't\",\n",
    "\"it\",\n",
    "\"it's\",\n",
    "\"its\",\n",
    "\"itself\",\n",
    "\"let's\",\n",
    "\"me\",\n",
    "\"more\",\n",
    "\"most\",\n",
    "\"mustn't\",\n",
    "\"my\",\n",
    "\"myself\",\n",
    "\"no\",\n",
    "\"nor\",\n",
    "\"not\",\n",
    "\"of\",\n",
    "\"off\",\n",
    "\"on\",\n",
    "\"once\",\n",
    "\"only\",\n",
    "\"or\",\n",
    "\"other\",\n",
    "\"ought\",\n",
    "\"our\",\n",
    "\"ours\",\n",
    "\"ourselves\",\n",
    "\"out\",\n",
    "\"over\",\n",
    "\"own\",\n",
    "\"same\",\n",
    "\"shan't\",\n",
    "\"she\",\n",
    "\"she'd\",\n",
    "\"she'll\",\n",
    "\"she's\",\n",
    "\"should\",\n",
    "\"shouldn't\",\n",
    "\"so\",\n",
    "\"some\",\n",
    "\"such\",\n",
    "\"than\",\n",
    "\"that\",\n",
    "\"that's\",\n",
    "\"the\",\n",
    "\"their\",\n",
    "\"theirs\",\n",
    "\"them\",\n",
    "\"themselves\",\n",
    "\"then\",\n",
    "\"there\",\n",
    "\"there's\",\n",
    "\"these\",\n",
    "\"they\",\n",
    "\"they'd\",\n",
    "\"they'll\",\n",
    "\"they're\",\n",
    "\"they've\",\n",
    "\"this\",\n",
    "\"those\",\n",
    "\"through\",\n",
    "\"to\",\n",
    "\"too\",\n",
    "\"under\",\n",
    "\"until\",\n",
    "\"up\",\n",
    "\"very\",\n",
    "\"was\",\n",
    "\"wasn't\",\n",
    "\"we\",\n",
    "\"we'd\",\n",
    "\"we'll\",\n",
    "\"we're\",\n",
    "\"we've\",\n",
    "\"were\",\n",
    "\"weren't\",\n",
    "\"what\",\n",
    "\"what's\",\n",
    "\"when\",\n",
    "\"when's\",\n",
    "\"where\",\n",
    "\"where's\",\n",
    "\"which\",\n",
    "\"while\",\n",
    "\"who\",\n",
    "\"who's\",\n",
    "\"whom\",\n",
    "\"why\",\n",
    "\"why's\",\n",
    "\"with\",\n",
    "\"won't\",\n",
    "\"would\",\n",
    "\"wouldn't\",\n",
    "\"you\",\n",
    "\"you'd\",\n",
    "\"you'll\",\n",
    "\"you're\",\n",
    "\"you've\",\n",
    "\"your\",\n",
    "\"yours\",\n",
    "\"yourself\",\n",
    "\"yourselves\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(class_weight='balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3=rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Metrics test\n",
    "expected=Y_test\n",
    "predicted=model3.predict(X_test)\n",
    "print('test data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "\n",
    "#Metrics train\n",
    "expected=Y_train\n",
    "predicted=model3.predict(X_train)\n",
    "print('training data \\n' + metrics.classification_report(expected, predicted))\n",
    "matrix=metrics.confusion_matrix(Y_train, predicted)\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
